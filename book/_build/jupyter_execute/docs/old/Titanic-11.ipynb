{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "070d11e9",
   "metadata": {},
   "source": [
    "# 1. 타이타닉 데이터 첫 걸음 떼기\n",
    "\n",
    "## 데이터 파일 이해하기\n",
    "데이터 분석 프로젝트를 시작할 때, 가장 먼저 마주하게 되는 것이 바로 데이터 파일들입니다. 타이타닉 생존자 예측 프로젝트에서는 세 가지 파일이 필요합니다. 이 파일들은 캐글(Kaggle)의 타이타닉 대회 페이지(https://www.kaggle.com/competitions/titanic/data)에서 다운로드할 수 있습니다.\n",
    "\n",
    "**train.csv**\n",
    "\n",
    "train.csv 파일은 모델을 학습시키기 위한 데이터입니다.\n",
    "이 파일에는 각 승객의 특징(예: 나이, 성별, 객실 등급 등)과 함께 해당 승객이 생존했는지 여부(Survived 컬럼)가 기록되어 있습니다. 모델은 이 데이터를 활용해 특징과 생존 여부 사이의 관계를 학습하게 됩니다.\n",
    "쉽게 말해, train.csv는 문제와 정답이 함께 실린 학습용 교재와 같습니다.\n",
    "\n",
    "**test.csv**\n",
    "\n",
    "test.csv 파일은 모델의 성능을 평가하기 위한 데이터입니다.\n",
    "이 파일에는 승객의 특징은 포함되어 있지만, 생존 여부(Survived)는 제공되지 않습니다. 우리가 만든 모델은 이 데이터를 입력받아 승객들이 생존했을지 여부를 예측해야 합니다.\n",
    "다르게 표현하자면, test.csv는 배운 내용을 확인하기 위한 시험 문제지와 같습니다.\n",
    "\n",
    "**gender_submission.csv**\n",
    "\n",
    "gender_submission.csv 파일은 최종 결과물을 제출하기 위한 파일입니다.\n",
    "test.csv에서 예측한 생존 여부를 이 파일의 규격에 맞춰 작성한 후, 대회 플랫폼에 제출합니다. 파일에는 승객 ID와 예측한 생존 여부가 포함됩니다.\n",
    "마치 시험 문제를 풀고 답을 정리해서 제출하는 답안지와 같은 역할을 합니다.\n",
    "\n",
    "세 파일 간의 관계를 교재-시험-답안지에 비유하면 아래와 같습니다:\n",
    "- train.csv(교재)로 모델을 학습시킨다.\n",
    "- 학습된 모델로 test.csv(시험문제) 데이터를 예측한다.\n",
    "- 예측 결과를 gender_submission.csv(답안지) 형태로 저장해 제출한다.\n",
    "\n",
    "\n",
    "\n",
    "## 데이터 들여다보기\n",
    "\n",
    "이제 세 개의 데이터 파일을 불러오겠습니다. 다음과 같이 프롬프트를 입력합니다:\n",
    "\n",
    "📝 **프롬프트**\n",
    "```\n",
    "train.csv, test.csv, gender_submission.csv 파일을 불러와서 \n",
    "각각 train, test, submission이라는 이름의 데이터프레임으로 저장해줘\n",
    "```\n",
    "\n",
    "💻 **코드 & 실행결과**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd0f813d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender_submission.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('gender_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2f28d9",
   "metadata": {},
   "source": [
    "위 코드는 세 개의 CSV 파일을 읽어오는 작업을 수행합니다. pd.read_csv()는 CSV(Comma-Separated Values) 파일을 읽어서 데이터프레임으로 변환하는 함수입니다. 데이터프레임은 엑셀의 스프레드시트처럼 행과 열로 구성된 2차원 형태의 데이터 구조입니다. 각각의 파일을 train, test, submission이라는 이름의 데이터프레임 변수에 저장했습니다. \n",
    "\n",
    "코드에서 `import pandas as pd`라는 부분이 있는데, 이는 pandas라는 데이터 분석 라이브러리를 불러오면서 'pd'라는 별명을 붙인 것입니다. 그래서 `pd.read_csv()`와 같이 'pd.'을 앞에 붙여서 pandas의 기능을 사용할 수 있는 것입니다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "그런데 위 코드를 실행하면 아무것도 출력되지 않습니다. 코드가 정상적으로 실행되어 데이터를 잘 읽어 들였는지 알 수가 없네요. 확인을 위해 각 데이터의 크기, 즉 행과 열의 수를 출력해보도록 하겠습니다.\n",
    "\n",
    "📝 **프롬프트**\n",
    "\n",
    "```\n",
    "세 데이터프레임의 행과 열 수를 출력해줘\n",
    "```\n",
    "\n",
    "💻 **코드 & 실행결과**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2fb69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train data shape:\", train.shape)\n",
    "print(\"test data shape:\", test.shape)\n",
    "print(\"submission data shape:\", submission.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14039ce5",
   "metadata": {},
   "source": [
    "위 결과는 다음과 같은 의미를 가집니다:\n",
    "\n",
    "- train 데이터는 891명의 승객 정보가 있으며, 각 승객마다 12개의 특성이 기록되어 있습니다.\n",
    "- test 데이터는 418명의 승객 정보가 있고, 11개의 특성이 있습니다. train 데이터보다 특성이 하나 적은 이유는 생존 여부(Survived)가 제외되어 있기 때문입니다.\n",
    "- submission 데이터는 test 데이터와 같은 418명의 승객에 대해 2개의 열(PassengerId와 Survived)만 가지고 있습니다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "이제 train 데이터의 내용을 자세히 살펴보겠습니다. 다음과 같이 프롬프트를 입력합니다:\n",
    "\n",
    "📝 **프롬프트**\n",
    "```\n",
    "train 데이터의 첫 5개 행을 보여줘\n",
    "```\n",
    "\n",
    "💻 **코드 & 실행결과**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6b10a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb42c947",
   "metadata": {},
   "source": [
    "train 데이터를 살펴보면 각 승객에 대한 다양한 정보가 기록되어 있습니다:\n",
    "- PassengerId: 승객 번호\n",
    "- Survived: 생존 여부 (1: 생존, 0: 사망)\n",
    "- Pclass: 객실 등급 (1: 1등석, 2: 2등석, 3: 3등석)\n",
    "- Name: 승객 이름\n",
    "- Sex: 성별\n",
    "- Age: 나이\n",
    "- SibSp: 함께 승선한 형제자매, 배우자 수\n",
    "- Parch: 함께 승선한 부모, 자녀 수\n",
    "- Ticket: 티켓 번호\n",
    "- Fare: 요금\n",
    "- Cabin: 객실 번호\n",
    "- Embarked: 승선 항구 (C: Cherbourg, Q: Queenstown, S: Southampton)\n",
    "\n",
    "이렇게 데이터를 살펴보면 우리가 예측에 사용할 수 있는 다양한 정보들이 있다는 것을 알 수 있습니다. 예를 들어, 객실 등급(Pclass)이나 성별(Sex), 나이(Age) 등은 생존 여부와 관련이 있을 것으로 추측할 수 있습니다.\n",
    "\n",
    "\n",
    "\n",
    "test 데이터도 살펴보겠습니다. 앞서 train 데이터를 볼 때 사용했던 head() 명령을 활용하면 되겠죠? train을 test로만 바꿔주면 됩니다.\n",
    "\n",
    "💻 **코드 & 실행결과**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338c9d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f665e9",
   "metadata": {},
   "source": [
    "test 데이터를 보면 train 데이터와 매우 비슷하지만, 한 가지 중요한 차이가 있습니다. 바로 'Survived' 열이 없다는 것입니다. 이는 당연한 것인데, test 데이터는 우리가 생존 여부를 예측해야 할 데이터이기 때문입니다.\n",
    "\n",
    "앞서 교재-시험-답안지 비유를 떠올려보면, test 데이터는 시험 문제지와 같습니다. 시험 문제지에는 답이 적혀있지 않은 것처럼, test 데이터에도 생존 여부가 없는 것입니다. 우리가 만들 인공지능 모델이 바로 이 test 데이터의 승객들에 대해 생존 여부를 예측하게 될 것입니다.\n",
    "\n",
    "\n",
    "\n",
    "마지막으로 제출 양식인 gender_submission.csv를 살펴보겠습니다. 이제는 익숙하시죠? head() 명령을 사용해서 앞부분 몇 행만 확인해보겠습니다.\n",
    "\n",
    "💻 **코드 & 실행결과**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278ab0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e85fce",
   "metadata": {},
   "source": [
    "이 파일은 우리가 제출할 답안의 형식을 보여줍니다. PassengerId는 test 데이터와 동일한 승객 번호이고, Survived는 우리가 예측한 생존 여부를 적는 곳입니다.\n",
    "\n",
    "재미있는 점은 이 파일의 이름이 'gender_submission.csv'라는 것입니다. 보통 다른 캐글 대회의 제출 양식에는 예측해야 할 값이 모두 0으로 되어 있는데, 타이타닉 대회에서는 성별에 기반한 예측 결과를 미리 제공합니다. 이는 타이타닉 대회가 많은 사람들의 '첫 번째 캐글 대회'이기 때문입니다. 초보자들이 참고할 수 있도록 간단한 예시 답안을 제공한 것이죠.\n",
    "\n",
    "\n",
    "\n",
    "## 결과 제출해보기\n",
    "\n",
    "우리는 아직 'Survived'를 예측하는 모델을 만들지 않았기 때문에, 이번 섹션에서는 일단 gender_submission.csv 파일을 아무런 변경없이 그대로 제출해 보겠습니다. 캐글의 타이타닉 페이지에서 'Submit Prediction' 버튼을 누르면 아래와 같은 창에서 파일을 올릴 수 있습니다. 'gender_submission.csv' 파일을 올려봅시다.\n",
    "\n",
    "```{figure} images/11-1.png\n",
    "---\n",
    "width: 600px\n",
    "---\n",
    "```\n",
    "\n",
    "\n",
    "제출결과로 0.76555를 받았습니다. 원고를 쓰는 시점에서 0.76555는 13,315 팀 중 9,643 등이네요. 순위는 'Leaderboard'에서 확인할 수 있습니다.\n",
    "\n",
    "```{figure} images/11-2.png\n",
    "---\n",
    "width: 600px\n",
    "---\n",
    "```\n",
    "\n",
    "이 대회에서 사용하는 평가지표는 accuracy 입니다. Accuracy는 분류 문제에서 종종 사용되는 평가지표로 전체 케이스 중에서 정확한 예측을 한 케이스의 비율입니다. 0.76555 * 418 명을 하면 320명이 나오네요. 생존 여부를 정확하게 예측한 경우가 320명이라는 의미입니다. 남자는 0(희생자), 여자는 1(생존자)로 예측한 간단한 모델이지만 꽤 높은 점수가 나왔습니다. 앞으로 계속 학습해 가며, 이 값을 넘는 좋은 예측 모델을 만들어 봅시다!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.11.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "source_map": [
   13,
   58,
   64,
   83,
   87,
   106,
   108,
   131,
   133,
   144,
   146
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}